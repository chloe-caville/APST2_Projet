{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Familiarize your self with the Gymnasium environment\n",
    "\n",
    "The aim of this notebook is to help you getting started with the [Gymnasium](https://gymnasium.farama.org) environment. Gymnasium (formerly Gym) is a toolkit for developing and comparing reinforcement learning algorithms. It supports teaching agents everything from walking to playing games like Pong or Pinball.\n",
    "\n",
    "We are now going to:\n",
    "\n",
    "    - see how to install the gym toolkit\n",
    "    - learn how to use it\n",
    "    - have fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation\n",
    "\n",
    "The simplest way to install gymnasium is to use *pip*. This is easily done, apart from a slight option activation to get all the available environments installed, using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Downloading gymnasium-0.27.1-py3-none-any.whl (883 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\sarra\\anaconda3\\lib\\site-packages (from gymnasium) (4.11.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\sarra\\anaconda3\\lib\\site-packages (from gymnasium) (1.21.5)\n",
      "Collecting gymnasium-notices>=0.0.1\n",
      "  Downloading gymnasium_notices-0.0.1-py3-none-any.whl (2.8 kB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\sarra\\anaconda3\\lib\\site-packages (from gymnasium) (2.0.0)\n",
      "Collecting jax-jumpy>=0.2.0\n",
      "  Downloading jax_jumpy-0.2.0-py3-none-any.whl (11 kB)\n",
      "Collecting typing-extensions>=4.3.0\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sarra\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.7.0)\n",
      "Installing collected packages: typing-extensions, jax-jumpy, gymnasium-notices, gymnasium\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.1.1\n",
      "    Uninstalling typing-extensions-4.1.1:\n",
      "      Successfully uninstalled typing-extensions-4.1.1\n",
      "Successfully installed gymnasium-0.27.1 gymnasium-notices-0.0.1 jax-jumpy-0.2.0 typing-extensions-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also have to install the *pygame* library as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygameNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pygame-2.1.3-cp39-cp39-win_amd64.whl (10.4 MB)\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.1.3\n"
     ]
    }
   ],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now all set to start learning how to interact with the gymnasium toolkit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interacting with the environment\n",
    "\n",
    "The gymnasium library is a collection of test problems, often called **environments**, that you can use to work out your reinforcement learning algorithms. These environments have a shared interface, allowing you to write general algorithms. Let's have a look at the CartPole environments and play a bunch of games.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, info = env.reset(seed=42)\n",
    "for _ in range(50):\n",
    "   action = env.action_space.sample()  # this is where you would insert your policy\n",
    "   observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "   if terminated or truncated:\n",
    "      observation, info = env.reset()\n",
    "env.close()\n",
    "pygame.display.quit()\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything went fine, you should have seen a window where \"someone\" played the CartPole game. Let me summarize what the above lines did. First we load the gymnasium library (but you should have already guessed it, no?). Next we create our first gym **environment** which here happens to be the CartPole game. We then initialize the environment from the *env.reset()* call while the *env.render()* call allows us to display the current game state. Next we just do a bunch of random actions using successive *env.step* calls, more details later. Finally we do not forget to close our environment.  \n",
    "\n",
    "Of course there are many available environments and you can get a peek either by browing the gym website or by invoking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to take a closer the look to our gym environment. We will briefly detail:\n",
    "- *action_space* which defines the action set, i.e., $\\mathcal{A}$ of the lecture notes;\n",
    "- *observation_space* which defines the state/observation space, i.e., $\\mathcal{X}$ of the lecture notes;\n",
    "- *reset* which is a method that (re)initialize the environment and outputs a initial state;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "Discrete(4)\n",
      "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "Discrete(16)\n",
      "(array([-0.03756223,  0.01419569, -0.03269762, -0.00353267], dtype=float32), {})\n",
      "(0, {'prob': 1})\n"
     ]
    }
   ],
   "source": [
    "env1 = gym.make(\"CartPole-v1\", render_mode = \"human\")\n",
    "init1 = env1.reset()\n",
    "env2 = gym.make(\"FrozenLake-v1\", render_mode = \"human\")\n",
    "init2 = env2.reset()\n",
    "\n",
    "print(env1.action_space)## -> Discrete(2) indicates that we have only 2 possible actions '0' and '1'\n",
    "print(env2.action_space)## -> Discrete(4) we now have 4 possible actions '0', ..., '4'\n",
    "\n",
    "print(env1.observation_space)## -> Box(4,) indicates that a state is a vector of size 4\n",
    "print(env2.observation_space)## -> Discrete(16) indicates that we have 16 possible states\n",
    "\n",
    "print(init1)## this is indeed a vector of size 4\n",
    "print(init2)## this is indeed an integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to see the main method which is *step*. It takes as an argument the action label, i.e., an integer, and performs this action to the current state of the environment and outputs four values:\n",
    "- a *state*, i.e., an element of the *observation_space*;\n",
    "- a *reward* which is a real number;\n",
    "- a *boolean* indicating if the user won the game;\n",
    "- a *boolean* indicating if the game was ended before winning, i.e., maximal number of moves reached.\n",
    "- a *dictionary* that gives useful information (for debugging purposes only).\n",
    "\n",
    "Let's try to perform an action to our *CartPole* problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.03030231,  0.16829158,  0.04409382, -0.29919973], dtype=float32), 1.0, False, False, {})\n",
      "[-0.02693648  0.3627582   0.03810983 -0.5776567 ]\n",
      "1.0\n",
      "False\n",
      "False\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "state = env1.reset()\n",
    "env1.render()\n",
    "print(env1.step(1))\n",
    "new_state, reward, done, truncated, info = env1.step(1)\n",
    "print(new_state) ## --> here the new state\n",
    "print(reward)## -> we have just been rewarded of 1\n",
    "print(done)## -> is the game over?\n",
    "print(truncated)## -> did you reach the maximum number of steps, i.e., you win\n",
    "print(info)## -> nothing to say"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which type of action did we just perform with the step(1) call?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Give your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Having fun\n",
    "\n",
    "Let's focus on the [FrozenLake environment](https://gymnasium.farama.org/environments/toy_text/frozen_lake). Please carefully read its description. Try to play a game using random moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sarra\\Documents\\APST2_Projet\\Lab 0\\GymIntro.ipynb Cellule 18\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sarra/Documents/APST2_Projet/Lab%200/GymIntro.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m : \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sarra/Documents/APST2_Projet/Lab%200/GymIntro.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     action \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39msample() \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sarra/Documents/APST2_Projet/Lab%200/GymIntro.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     new_state, reward, done, truncated, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sarra/Documents/APST2_Projet/Lab%200/GymIntro.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     env\u001b[39m.\u001b[39mrender()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sarra/Documents/APST2_Projet/Lab%200/GymIntro.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mif\u001b[39;00m done: \n",
      "File \u001b[1;32mc:\\Users\\sarra\\Anaconda3\\lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:51\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     41\u001b[0m     \u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     52\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     54\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\sarra\\Anaconda3\\lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:38\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     37\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\sarra\\Anaconda3\\lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\sarra\\Anaconda3\\lib\\site-packages\\gymnasium\\envs\\toy_text\\frozen_lake.py:308\u001b[0m, in \u001b[0;36mFrozenLakeEnv.step\u001b[1;34m(self, a)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlastaction \u001b[39m=\u001b[39m a\n\u001b[0;32m    307\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 308\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender()\n\u001b[0;32m    309\u001b[0m \u001b[39mreturn\u001b[39;00m (\u001b[39mint\u001b[39m(s), r, t, \u001b[39mFalse\u001b[39;00m, {\u001b[39m\"\u001b[39m\u001b[39mprob\u001b[39m\u001b[39m\"\u001b[39m: p})\n",
      "File \u001b[1;32mc:\\Users\\sarra\\Anaconda3\\lib\\site-packages\\gymnasium\\envs\\toy_text\\frozen_lake.py:338\u001b[0m, in \u001b[0;36mFrozenLakeEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_render_text()\n\u001b[0;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# self.render_mode in {\"human\", \"rgb_array\"}:\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_render_gui(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender_mode)\n",
      "File \u001b[1;32mc:\\Users\\sarra\\Anaconda3\\lib\\site-packages\\gymnasium\\envs\\toy_text\\frozen_lake.py:432\u001b[0m, in \u001b[0;36mFrozenLakeEnv._render_gui\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    430\u001b[0m     pygame\u001b[39m.\u001b[39mevent\u001b[39m.\u001b[39mpump()\n\u001b[0;32m    431\u001b[0m     pygame\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m--> 432\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclock\u001b[39m.\u001b[39;49mtick(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetadata[\u001b[39m\"\u001b[39;49m\u001b[39mrender_fps\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    433\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    434\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mtranspose(\n\u001b[0;32m    435\u001b[0m         np\u001b[39m.\u001b[39marray(pygame\u001b[39m.\u001b[39msurfarray\u001b[39m.\u001b[39mpixels3d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_surface)), axes\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m    436\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %load solutions/FrozenLake.py\n",
    "env = gym.make(\"FrozenLake-v1\", render_mode=\"human\")\n",
    "state = env.reset()\n",
    "\n",
    "while True : \n",
    "    action = env.action_space.sample() \n",
    "    new_state, reward, done, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "    if done: \n",
    "        state = env.reset()\n",
    "        continue\n",
    "\n",
    "print(\"Game over!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7673fce31fe4afe50b4d7357ba4e3f000f877c9b2250741ca11e5d63029f695"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
